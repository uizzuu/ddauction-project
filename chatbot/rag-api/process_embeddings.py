import os
from dotenv import load_dotenv
from pathlib import Path
import json
from pinecone import Pinecone
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import MarkdownTextSplitter
from langchain_pinecone import Pinecone as LangchainPinecone

# --- í™˜ê²½ ì„¤ì • ë¡œë“œ ---
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_ENVIRONMENT = os.getenv("PINECONE_ENVIRONMENT")
INDEX_NAME = os.getenv("INDEX_NAME", "ddauction-db")

# Markdown íŒŒì¼ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬
MD_DIR = Path("./rag-api/docs")

if not all([OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_ENVIRONMENT]):
    raise ValueError("âš ï¸ í™˜ê²½ ë³€ìˆ˜(OPENAI_API_KEY, PINECONE_API_KEY, PINECONE_ENVIRONMENT)ë¥¼ ëª¨ë‘ ì„¤ì •í•˜ì„¸ìš”.")

# =========================
# 1. Pinecone ë° Embeddings ì´ˆê¸°í™”
# =========================
try:
    # Langchainì—ì„œ ì‚¬ìš©í•  Embeddings ëª¨ë¸ (1536ì°¨ì›)
    embeddings = OpenAIEmbeddings(
        model="text-embedding-3-small",
        openai_api_key=OPENAI_API_KEY
    )

    # Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)

    print(f"âœ… Pinecone í™˜ê²½ ë° OpenAI Embeddings ì´ˆê¸°í™” ì™„ë£Œ.")

except Exception as e:
    print(f"âŒ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    exit()


# =========================
# 2. ë¬¸ì„œ ì „ì²˜ë¦¬ ë° ì²­í¬ ë¶„í• 
# =========================
def process_documents(doc_path: Path):
    """ì§€ì •ëœ ë””ë ‰í† ë¦¬ì—ì„œ .md íŒŒì¼ì„ ì½ê³  ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤."""

    # MarkdownTextSplitter ì´ˆê¸°í™”: 500ì ë‹¨ìœ„ë¡œ, 50ì ì¤‘ë³µì„ í—ˆìš©
    splitter = MarkdownTextSplitter(chunk_size=500, chunk_overlap=50)

    documents = []

    for md_file in doc_path.glob("*.md"):
        print(f"ğŸ” ë¬¸ì„œ ë¡œë“œ ë° ë¶„í•  ì‹œì‘: {md_file.name}")

        # íŒŒì¼ ë‚´ìš©ì„ ë¡œë“œ
        content = md_file.read_text(encoding="utf-8")

        # ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í• 
        chunks = splitter.split_text(content)

        # ì²­í¬ë§ˆë‹¤ ë©”íƒ€ë°ì´í„° ì¶”ê°€
        for i, chunk in enumerate(chunks):
            # Pineconeì— ì €ì¥í•  ë©”íƒ€ë°ì´í„° ì •ì˜
            metadata = {
                "source": md_file.name,
                "document_id": md_file.stem,  # íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
                "chunk_id": f"{md_file.stem}_{i}",
                "document": chunk  # ì›ë³¸ í…ìŠ¤íŠ¸ ì²­í¬
            }
            documents.append((chunk, metadata))

    print(f"âœ… ì´ {len(documents)}ê°œì˜ ë¬¸ì„œ ì²­í¬ ìƒì„± ì™„ë£Œ.")
    return documents


# =========================
# 3. Pineconeì— ì—…ë¡œë“œ
# =========================
def ingest_to_pinecone(documents):
    """ë¶„í• ëœ ë¬¸ì„œ ì²­í¬ë¥¼ Pinecone ì¸ë±ìŠ¤ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤."""

    if INDEX_NAME not in pc.list_indexes().names:
        print(f"ğŸš¨ ì¸ë±ìŠ¤ '{INDEX_NAME}'ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
        # Pinecone Serverless ì¸ë±ìŠ¤ ìƒì„± (ìµœì‹  ê¶Œì¥)
        pc.create_index(
            name=INDEX_NAME,
            dimension=1536,  # text-embedding-3-smallì˜ ì°¨ì›
            metric="cosine"
        )
        print(f"âœ… ì¸ë±ìŠ¤ '{INDEX_NAME}' ìƒì„± ì™„ë£Œ.")

    # Langchainì˜ Pinecone ìœ í‹¸ë¦¬í‹°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì—…ë¡œë“œ
    try:
        LangchainPinecone.from_texts(
            texts=[doc[0] for doc in documents],
            embedding=embeddings,
            index_name=INDEX_NAME,
            metadatas=[doc[1] for doc in documents]
        )
        print(f"ğŸ‰ {len(documents)}ê°œì˜ ì²­í¬ê°€ Pinecone ì¸ë±ìŠ¤ '{INDEX_NAME}'ì— ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ Pinecone ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")


# =========================
# ë©”ì¸ ì‹¤í–‰
# =========================
if __name__ == "__main__":
    if not MD_DIR.exists():
        print(f"âŒ ë¬¸ì„œ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MD_DIR}. 'pdf_converter.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ê³  ë¬¸ì„œë¥¼ ë„£ì–´ì£¼ì„¸ìš”.")
    else:
        # 1. ë¬¸ì„œ ì²˜ë¦¬
        processed_documents = process_documents(MD_DIR)

        if processed_documents:
            # 2. Pineconeì— ì—…ë¡œë“œ
            ingest_to_pinecone(processed_documents)
        else:
            print("â— ì—…ë¡œë“œí•  .md íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œë¥¼ í™•ì¸í•˜ì„¸ìš”.")