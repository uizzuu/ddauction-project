# import os
# import io
# import base64
# import requests
# from typing import List, Dict, Optional
# from PIL import Image
# import torch
# import numpy as np
# from transformers import CLIPProcessor, CLIPModel
# from sklearn.metrics.pairwise import cosine_similarity
# from dotenv import load_dotenv
#
# load_dotenv()
#
#
# class ImageRecommendationEngine:
#     """
#     ì´ë¯¸ì§€ ê¸°ë°˜ ìƒí’ˆ ì¶”ì²œ ì—”ì§„
#     - CLIP ëª¨ë¸ì„ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê³„ì‚°
#     - ì—…ë¡œë“œëœ ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ ìƒí’ˆ ì¶”ì²œ
#     """
#
#     def __init__(self, spring_api_base: str):
#         self.spring_api_base = spring_api_base
#
#         # CLIP ëª¨ë¸ ë¡œë“œ (í•œ ë²ˆë§Œ ì´ˆê¸°í™”)
#         print("ğŸ”„ CLIP ëª¨ë¸ ë¡œë”© ì¤‘...")
#         self.model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
#         self.processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")
#         self.device = "cuda" if torch.cuda.is_available() else "cpu"
#         self.model.to(self.device)
#         print(f"âœ… CLIP ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (device: {self.device})")
#
#     def _safe_request(self, url: str, timeout: int = 5) -> Optional[Dict]:
#         """ì•ˆì „í•œ HTTP ìš”ì²­"""
#         try:
#             response = requests.get(url, timeout=timeout)
#             if response.ok:
#                 return response.json()
#             return None
#         except Exception as e:
#             print(f"âš ï¸ ìš”ì²­ ì‹¤íŒ¨ ({url}): {e}")
#             return None
#
#     def _fetch_all_products(self) -> List[Dict]:
#         """ì „ì²´ ìƒí’ˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
#         data = self._safe_request(f"{self.spring_api_base}/api/products")
#         return data or []
#
#     def _decode_base64_image(self, base64_str: str) -> Optional[Image.Image]:
#         """Base64 ë¬¸ìì—´ì„ PIL Imageë¡œ ë³€í™˜"""
#         try:
#             # data:image/jpeg;base64, ì ‘ë‘ì‚¬ ì œê±°
#             if "," in base64_str:
#                 base64_str = base64_str.split(",")[1]
#
#             image_bytes = base64.b64decode(base64_str)
#             image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
#             return image
#         except Exception as e:
#             print(f"âŒ ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {e}")
#             return None
#
#     def _load_image_from_url(self, image_url: str) -> Optional[Image.Image]:
#         """URLì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ"""
#         try:
#             response = requests.get(image_url, timeout=5)
#             if response.ok:
#                 image = Image.open(io.BytesIO(response.content)).convert("RGB")
#                 return image
#             return None
#         except Exception as e:
#             print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ ({image_url}): {e}")
#             return None
#
#     def _extract_image_features(self, image: Image.Image) -> np.ndarray:
#         """ì´ë¯¸ì§€ì—ì„œ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ"""
#         try:
#             inputs = self.processor(images=image, return_tensors="pt")
#             inputs = {k: v.to(self.device) for k, v in inputs.items()}
#
#             with torch.no_grad():
#                 image_features = self.model.get_image_features(**inputs)
#
#             # ì •ê·œí™”
#             image_features = image_features / image_features.norm(dim=-1, keepdim=True)
#             return image_features.cpu().numpy()
#         except Exception as e:
#             print(f"âŒ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
#             return None
#
#     def _calculate_similarity(
#             self,
#             query_features: np.ndarray,
#             target_features: np.ndarray
#     ) -> float:
#         """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
#         try:
#             similarity = cosine_similarity(query_features, target_features)[0][0]
#             return float(similarity)
#         except Exception as e:
#             print(f"âŒ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
#             return 0.0
#
#     def recommend_by_image(
#             self,
#             image_base64: str,
#             limit: int = 10,
#             category_filter: Optional[str] = None,
#             min_similarity: float = 0.3
#     ) -> List[Dict]:
#         """
#         ì´ë¯¸ì§€ ê¸°ë°˜ ìƒí’ˆ ì¶”ì²œ
#
#         Args:
#             image_base64: Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€
#             limit: ë°˜í™˜í•  ìƒí’ˆ ìˆ˜
#             category_filter: ì¹´í…Œê³ ë¦¬ í•„í„° (ì„ íƒ)
#             min_similarity: ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’
#
#         Returns:
#             ìœ ì‚¬ë„ ë†’ì€ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸
#         """
#         print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ ê¸°ë°˜ ì¶”ì²œ ì‹œì‘ (limit={limit})")
#
#         # 1. ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ì²˜ë¦¬
#         query_image = self._decode_base64_image(image_base64)
#         if query_image is None:
#             raise ValueError("ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")
#
#         # 2. ì¿¼ë¦¬ ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
#         query_features = self._extract_image_features(query_image)
#         if query_features is None:
#             raise ValueError("ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨")
#
#         # 3. ì „ì²´ ìƒí’ˆ ê°€ì ¸ì˜¤ê¸°
#         all_products = self._fetch_all_products()
#         print(f"ğŸ“¦ ìƒí’ˆ {len(all_products)}ê°œ ë¡œë“œë¨")
#
#         # 4. ê° ìƒí’ˆì˜ ì´ë¯¸ì§€ì™€ ìœ ì‚¬ë„ ê³„ì‚°
#         scored_products = []
#         for product in all_products:
#             product_id = product.get("productId")
#
#             # ìƒíƒœ í™•ì¸
#             status = product.get("productStatus", "")
#             if status not in ["ACTIVE", "PAUSED"]:
#                 continue
#
#             # ì¹´í…Œê³ ë¦¬ í•„í„°
#             if category_filter:
#                 if product.get("productCategoryType") != category_filter:
#                     continue
#
#             # ìƒí’ˆ ì´ë¯¸ì§€ URL ê°€ì ¸ì˜¤ê¸°
#             image_urls = product.get("imageUrls", [])
#             if not image_urls:
#                 continue
#
#             # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë¡œ ìœ ì‚¬ë„ ê³„ì‚°
#             product_image = self._load_image_from_url(image_urls[0])
#             if product_image is None:
#                 continue
#
#             product_features = self._extract_image_features(product_image)
#             if product_features is None:
#                 continue
#
#             similarity = self._calculate_similarity(query_features, product_features)
#
#             # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’ ì ìš©
#             if similarity < min_similarity:
#                 continue
#
#             scored_products.append({
#                 **product,
#                 "similarity_score": round(similarity, 4),
#                 "match_type": "visual"
#             })
#
#         # 5. ìœ ì‚¬ë„ ê¸°ì¤€ ì •ë ¬
#         scored_products.sort(key=lambda x: x["similarity_score"], reverse=True)
#         result = scored_products[:limit]
#
#         print(f"âœ… ì´ë¯¸ì§€ ê¸°ë°˜ ì¶”ì²œ ì™„ë£Œ: {len(result)}ê°œ ìƒí’ˆ")
#         return result
#
#     def recommend_by_product_image(
#             self,
#             product_id: int,
#             limit: int = 6,
#             exclude_same_product: bool = True
#     ) -> List[Dict]:
#         """
#         íŠ¹ì • ìƒí’ˆì˜ ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ ìƒí’ˆ ì¶”ì²œ
#
#         Args:
#             product_id: ê¸°ì¤€ ìƒí’ˆ ID
#             limit: ë°˜í™˜í•  ìƒí’ˆ ìˆ˜
#             exclude_same_product: ê°™ì€ ìƒí’ˆ ì œì™¸ ì—¬ë¶€
#
#         Returns:
#             ì‹œê°ì ìœ¼ë¡œ ìœ ì‚¬í•œ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸
#         """
#         print(f"ğŸ” ìƒí’ˆ ì´ë¯¸ì§€ ê¸°ë°˜ ìœ ì‚¬ ìƒí’ˆ ê²€ìƒ‰: product_id={product_id}")
#
#         # 1. ëŒ€ìƒ ìƒí’ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
#         target = self._safe_request(
#             f"{self.spring_api_base}/api/products/{product_id}"
#         )
#         if not target:
#             raise ValueError(f"ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {product_id}")
#
#         image_urls = target.get("imageUrls", [])
#         if not image_urls:
#             raise ValueError("ìƒí’ˆ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
#
#         # 2. ëŒ€ìƒ ìƒí’ˆ ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
#         target_image = self._load_image_from_url(image_urls[0])
#         if target_image is None:
#             raise ValueError("ìƒí’ˆ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨")
#
#         target_features = self._extract_image_features(target_image)
#         if target_features is None:
#             raise ValueError("ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨")
#
#         # 3. ì „ì²´ ìƒí’ˆê³¼ ë¹„êµ
#         all_products = self._fetch_all_products()
#         scored_products = []
#
#         for product in all_products:
#             pid = product.get("productId")
#
#             # ê°™ì€ ìƒí’ˆ ì œì™¸
#             if exclude_same_product and pid == product_id:
#                 continue
#
#             # ìƒíƒœ í™•ì¸
#             status = product.get("productStatus", "")
#             if status not in ["ACTIVE", "PAUSED"]:
#                 continue
#
#             # ì´ë¯¸ì§€ ìœ ì‚¬ë„ ê³„ì‚°
#             prod_image_urls = product.get("imageUrls", [])
#             if not prod_image_urls:
#                 continue
#
#             prod_image = self._load_image_from_url(prod_image_urls[0])
#             if prod_image is None:
#                 continue
#
#             prod_features = self._extract_image_features(prod_image)
#             if prod_features is None:
#                 continue
#
#             similarity = self._calculate_similarity(target_features, prod_features)
#
#             scored_products.append({
#                 **product,
#                 "similarity_score": round(similarity, 4),
#                 "match_type": "visual"
#             })
#
#         # 4. ì •ë ¬ ë° ë°˜í™˜
#         scored_products.sort(key=lambda x: x["similarity_score"], reverse=True)
#         result = scored_products[:limit]
#
#         print(f"âœ… ì‹œê°ì  ìœ ì‚¬ ìƒí’ˆ: {len(result)}ê°œ ë°œê²¬")
#         return result
#
#
# # ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
# SPRING_API_BASE = os.getenv("SPRING_API_BASE", "http://localhost:8080")
# image_recommendation_engine = ImageRecommendationEngine(SPRING_API_BASE)